{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promotional Model for Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "In this dataset you can find the below columns:\n",
    "account_id, product_id, MAG, AG, date_id, promo_flag, promo_discount_perc, base_demand, ordered_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample there is only one account,\n",
    "\n",
    "MAG:highest product hierarchy level \n",
    "\n",
    "AG:next highest prodct level\n",
    "\n",
    "product id: SKU that the model should be able to predict the final order_units for it\n",
    "\n",
    "So,  MAG-> AG -> product_id is the product hierarchy\n",
    "\n",
    "date_id: an integer represents a day in a week,\n",
    "\n",
    "promo_flag: indicates when a promotion was reported, \n",
    "\n",
    "promo_discount_perc: the promotion percentage calculated from the sales price,\n",
    "\n",
    "base_demand: represents the product demand in the absence of any promotion, \n",
    "\n",
    "ordered_units: final forecast for the model to generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CODE (for Model Selection, by running Model Validation on 'base_promo_trainset.csv'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('base_promo_trainset.csv')\n",
    "# Rajeev: let us do a data preprocessing and see the observe the data before directly assigning test and train sets. \n",
    "#Hence commenting below\n",
    "#X = dataset.iloc[:, 5:8].values\n",
    "#y = dataset.iloc[:, 8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   account_id  product_id  MAG   AG  date_id  promo_flag  promo_discount_perc  \\\n",
      "0           1           9  E01  638      738           0             0.000000   \n",
      "1           1          10  E01  638      738           0             0.000000   \n",
      "2           1          10  E01  638      745           0             0.000000   \n",
      "3           1          10  E01  638      752           0             5.031578   \n",
      "4           1          10  E01  638      759           0             3.331446   \n",
      "\n",
      "   base_demand  ordered_units  \n",
      "0         18.0             89  \n",
      "1         97.0             97  \n",
      "2        271.0            271  \n",
      "3        120.0            120  \n",
      "4         64.0             64  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id    product_id            AG       date_id    promo_flag  \\\n",
      "count     15347.0  15347.000000  15347.000000  15347.000000  15347.000000   \n",
      "mean          1.0   2846.052388   4151.085750   1119.672640      0.234313   \n",
      "std           0.0   1678.818820   2602.233166    221.784145      0.423582   \n",
      "min           1.0      9.000000    620.000000    738.000000      0.000000   \n",
      "25%           1.0    609.000000   3010.000000    927.000000      0.000000   \n",
      "50%           1.0   3739.000000   3157.000000   1123.000000      0.000000   \n",
      "75%           1.0   3944.000000   7160.000000   1312.000000      0.000000   \n",
      "max           1.0   5073.000000   8958.000000   1494.000000      1.000000   \n",
      "\n",
      "       promo_discount_perc   base_demand  ordered_units  \n",
      "count         15347.000000  15347.000000   15347.000000  \n",
      "mean              4.884157    241.435670     303.245129  \n",
      "std              10.138480    655.944153     916.858783  \n",
      "min             -57.989063      0.000000   -1917.000000  \n",
      "25%               0.000000      0.000000       0.000000  \n",
      "50%               0.000000      9.629630       8.000000  \n",
      "75%               3.723648    198.587108     243.500000  \n",
      "max              99.860810   9186.000000   27187.000000  \n",
      "\n",
      " Visualize the unique classes on each of variables\n",
      "MAG: ['E01' 'E15' 'I26' 'I36' 'M41' 'W91']\n",
      "AG: [ 620  638 3010 3079 3149 3155 3157 3160 3371 3568 3580 3590 5008 5041\n",
      " 5100 7160 7366 7456 8189 8190 8193 8194 8871 8873 8958]\n",
      "product_id: [   9   10   11   13   26   28   40   43   51  143  144  145  149  167\n",
      "  168  175  185  211  213  218  224  229  234  237  239  240  276  277\n",
      "  282  284  286  287  288  289  290  292  294  296  316  609 1640 1645\n",
      " 1947 1948 1957 1960 1964 1967 1973 3233 3234 3240 3241 3244 3245 3248\n",
      " 3250 3257 3260 3264 3266 3267 3270 3278 3290 3673 3681 3686 3691 3693\n",
      " 3712 3714 3720 3734 3739 3740 3741 3745 3764 3765 3766 3768 3788 3789\n",
      " 3794 3802 3808 3809 3813 3827 3833 3835 3838 3842 3843 3879 3881 3891\n",
      " 3893 3903 3905 3906 3909 3914 3922 3924 3927 3928 3929 3930 3940 3944\n",
      " 3951 3953 3955 3962 3964 3969 3984 3986 3988 3992 3993 3996 3999 4000\n",
      " 4006 4007 4008 4010 4012 4016 4022 4023 4024 4900 4903 4907 4912 4914\n",
      " 5024 5025 5030 5032 5033 5036 5056 5067 5072 5073]\n",
      "account_id: [1]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.describe())\n",
    "\n",
    "# Rajeev: visualize the unique classes on each of variables.\n",
    "print('\\n Visualize the unique classes on each of variables')\n",
    "print('MAG: '+str(np.unique(dataset['MAG'])))\n",
    "print('AG: '+str(np.unique(dataset['AG'])))\n",
    "print('product_id: '+str(np.unique(dataset['product_id'])))\n",
    "print('account_id: '+str(np.unique(dataset['account_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique products \n",
      "\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# Let us see how many unique products are there.\n",
    "dataset['uniqueprod'] = dataset['MAG'].astype(str)+'_'+dataset['AG'].astype(str)+'_'+dataset['product_id'].astype(str)\n",
    "print('Number of Unique products \\n')\n",
    "print(len(np.unique(dataset['uniqueprod'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Looking at the data set , it makes sense to use Time Series forcasting of 150 products over the time for 15k samples. \n",
    "# On an avarage 100 samples should be sufficient to build  Time Series forecasting model, that captures the demand well.\n",
    "\n",
    "# Since I could not find sufficient time this week, I will tune the existing model to perform better.\n",
    "\n",
    "# either we can build a decision tree(random forest, XGBOOST) based method. In the decision tree model 'date_id' doesnt make sense.\n",
    "\n",
    "#print(dataset.isnull()) Rajeev: commented this line since in a long dataframe we cant actually see \n",
    "# which is True and which is False. Below line should print NaN values\n",
    "print(dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can observe there are no missing values in the given dataset, we can skip using Imputer funtion to fill out the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking care of missing data\n",
    "\n",
    "#from sklearn.preprocessing import Imputer\n",
    "#imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "#imputer = imputer.fit(X[:, 5:8])\n",
    "#X[:, 5:8] = imputer.transform(X[:, 5:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Size of Existing Dataset: 15347\n",
      "\n",
      " Size of Existing Dataset after removing -negavtive discounts: 15347\n",
      "\n",
      " Size of Existing Dataset after removing outlier discount % : 15192\n"
     ]
    }
   ],
   "source": [
    "#since the promo discount of -57% doesnt make sense and we clean the values less than zero. \n",
    "# I'm not sure what is actually negative discount means. Since we cant sell products more than MRP. Hence cleaning it\n",
    "# Also the discount of 99.86% also doesnot make sense. In this case we see 99.5 and 0.005 percentile or 1.5 times IQR data \n",
    "#to be outliers. # Let us check these values.\n",
    "print('\\n Size of Existing Dataset: '+str(len(dataset)))\n",
    "#dataset['promo_discount_perc']=np.where(dataset['promo_discount_perc']<=0,0,dataset['promo_discount_perc'])\n",
    "\n",
    "print('\\n Size of Existing Dataset after removing -negavtive discounts: '+str(len(dataset)))\n",
    "dataset= dataset[dataset['promo_discount_perc']<dataset['promo_discount_perc'].quantile(0.995)]\n",
    "dataset= dataset[dataset['promo_discount_perc']>dataset['promo_discount_perc'].quantile(0.005)]\n",
    "\n",
    "print('\\n Size of Existing Dataset after removing outlier discount % : '+str(len(dataset)))\n",
    "\n",
    "# we can do these similar exercises to remove outliers on the other variables are well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id   AG  promo_flag  promo_discount_perc  base_demand  E01_638_91  \\\n",
      "0           9  638           0             0.000000         18.0           1   \n",
      "1          10  638           0             0.000000         97.0           0   \n",
      "2          10  638           0             0.000000        271.0           0   \n",
      "3          10  638           0             5.031578        120.0           0   \n",
      "4          10  638           0             3.331446         64.0           0   \n",
      "\n",
      "   E01_638_101  E01_638_131  E01_638_261  E01_620_431  ...  E01_620_40161  \\\n",
      "0            0            0            0            0  ...              0   \n",
      "1            1            0            0            0  ...              0   \n",
      "2            1            0            0            0  ...              0   \n",
      "3            1            0            0            0  ...              0   \n",
      "4            1            0            0            0  ...              0   \n",
      "\n",
      "   E01_620_40221  W91_3010_49121  W91_3010_49141  E01_620_50241  \\\n",
      "0              0               0               0              0   \n",
      "1              0               0               0              0   \n",
      "2              0               0               0              0   \n",
      "3              0               0               0              0   \n",
      "4              0               0               0              0   \n",
      "\n",
      "   I36_5041_50301  E01_7456_50331  E01_620_50361  E01_5100_50721  \\\n",
      "0               0               0              0               0   \n",
      "1               0               0              0               0   \n",
      "2               0               0              0               0   \n",
      "3               0               0              0               0   \n",
      "4               0               0              0               0   \n",
      "\n",
      "   E01_5100_50731  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "\n",
      "[5 rows x 155 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mag=list(pd.Series(dataset['uniqueprod']).unique())\n",
    "for i in range(len(mag)):\n",
    "    ttl=mag[i]\n",
    "    ttl1=ttl+'1'\n",
    "    dataset[ttl1] = dataset['uniqueprod'].str.contains(ttl)\n",
    "    dataset[ttl1] = dataset[ttl1].map({True: 1, False: 0})\n",
    "\n",
    "del dataset['MAG']\n",
    "y= dataset['ordered_units']\n",
    "del  dataset['ordered_units']\n",
    "del dataset['account_id']\n",
    "del dataset['date_id']\n",
    "del dataset['uniqueprod'] \n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into the Training set and Test set from the training dataset file for model selection\n",
    "X = dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Not required in Random Forest case)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc_X = StandardScaler()\n",
    "#X_train = sc_X.fit_transform(X_train)\n",
    "#X_test = sc_X.transform(X_test)\n",
    "#sc_y = StandardScaler()\n",
    "#y_train = sc_y.fit_transform(y_train.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=-1,\n",
       "                                             oob_score=False, random_state=1234,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
       "                         'max_features': [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7,\n",
       "                                          0.8, 0.9],\n",
       "                         'n_estimators': [5, 10, 25, 35, 40, 50, 60, 75, 90,\n",
       "                                          100, 120, 150, 170, 190, 200, 220,\n",
       "                                          250]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the grid search cv to find the optimum parameters, this can be fine tuned with more effort.\n",
    "# randomized search cv also can be used in case further tune the model but it is quite slow.\n",
    "# set n_jobs=-1 for parallel run\n",
    "rfr=RandomForestRegressor(random_state=1234,n_jobs=-1)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [5,10,25,35,40,50,60,75,90,100,120,150,170,190,200,220,250],\n",
    "    'max_features': [0.4,0.45,0.5, 0.55,0.6, 0.65, 0.7,0.8, 0.9],\n",
    "    'max_depth' : [6,7,8,9,10,11,12,13,14]\n",
    "}\n",
    "\n",
    "CV_rfr = GridSearchCV(estimator=rfr, param_grid=param_grid, cv= 5,n_jobs=-1)\n",
    "CV_rfr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 14, 'max_features': 0.7, 'n_estimators': 50}"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=14,\n",
       "                      max_features=0.7, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "                      oob_score=False, random_state=1234, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Decision Tree Regression to the dataset\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=50, max_depth=14,max_features= 0.7, random_state = 1234,n_jobs=-1)\n",
    "#regressor_1 = RandomForestRegressor(n_estimators=10, random_state = 0)\n",
    "#regressor = cross_val_score(regressor_1, X_train, y_train, cv =10)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting new results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9069360083770887\n"
     ]
    }
   ],
   "source": [
    "# Calculating r-squared using metrics class from sklearn\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.r2_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"RSquare: %0.2f (+/- %0.2f)\" % (regressor.mean(), regressor.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.556951938812254\n",
      "238.5522222733764\n"
     ]
    }
   ],
   "source": [
    "#calculating average absolute error \n",
    "error = abs(y_pred - y_test)\n",
    "print(error.mean())\n",
    "print(error.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          ordered_units   R-squared:                       0.759\n",
      "Model:                            OLS   Adj. R-squared:                  0.759\n",
      "Method:                 Least Squares   F-statistic:                     4779.\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):               0.00\n",
      "Time:                        07:40:41   Log-Likelihood:            -1.1340e+05\n",
      "No. Observations:               15192   AIC:                         2.268e+05\n",
      "Df Residuals:                   15181   BIC:                         2.269e+05\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -29.4195      9.140     -3.219      0.001     -47.335     -11.503\n",
      "x1            -0.0058      0.002     -2.655      0.008      -0.010      -0.002\n",
      "x2             0.0048      0.001      3.475      0.001       0.002       0.007\n",
      "x3           -30.2823     15.353     -1.972      0.049     -60.375      -0.189\n",
      "x4            12.8533      0.686     18.729      0.000      11.508      14.199\n",
      "x5             1.1255      0.005    212.663      0.000       1.115       1.136\n",
      "x6           -73.2893     43.035     -1.703      0.089    -157.644      11.065\n",
      "x7           -14.4162     41.520     -0.347      0.728     -95.801      66.969\n",
      "x8           -44.9223     41.578     -1.080      0.280    -126.420      36.575\n",
      "x9             9.4507     41.684      0.227      0.821     -72.256      91.157\n",
      "x10           24.0665     41.539      0.579      0.562     -57.354     105.487\n",
      "==============================================================================\n",
      "Omnibus:                    27849.403   Durbin-Watson:                   1.065\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         54477293.080\n",
      "Skew:                          13.555   Prob(JB):                         0.00\n",
      "Kurtosis:                     295.108   Cond. No.                     7.48e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.48e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Calculating the stats metrices having p value, r-squared and adjusted r-sqaurd values\n",
    "import statsmodels.api as sm\n",
    "X = np.append(arr = np.ones((len(dataset),1)).astype(int), values= X, axis = 1 )\n",
    "\n",
    "X_opt = X[:, [0,1,2,3,4,5,6,7,8,9,10]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "print(regressor_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the actual and predicted value\n",
    "plt.plot(y_pred, 'o', color = 'red')\n",
    "plt.plot(y_test, 'x', color= 'blue')\n",
    "plt.title('Predicted Value(o) vs. Actual Value(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CODE (for Prediction on given Test dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "# Rajeev; Using the data read earlier\n",
    "dataset = pd.read_csv('base_promo_trainset.csv')\n",
    "\n",
    "#X_train = dataset_train.iloc[:, 5:8].values\n",
    "#y_train = dataset_train.iloc[:, 8].values\n",
    "\n",
    "dataset_test = pd.read_csv('base_promo_testset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   account_id  product_id  MAG   AG  date_id  promo_flag  promo_discount_perc  \\\n",
      "0           1          10  E01  638     1501           0             0.000000   \n",
      "1           1          10  E01  638     1508           0             0.000000   \n",
      "2           1          10  E01  638     1515           0             0.000000   \n",
      "3           1          13  E01  638     1501           0             0.088674   \n",
      "4           1          13  E01  638     1508           0             0.088674   \n",
      "\n",
      "   base_demand  ordered_units  \n",
      "0          0.0            NaN  \n",
      "1          0.0            NaN  \n",
      "2          0.0            NaN  \n",
      "3          4.0            NaN  \n",
      "4          0.0            NaN  \n"
     ]
    }
   ],
   "source": [
    "print(dataset_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id   product_id           AG      date_id  promo_flag  \\\n",
      "count       542.0   542.000000   542.000000   542.000000  542.000000   \n",
      "mean          1.0  2836.822878  4175.957565  1510.673432    0.081181   \n",
      "std           0.0  1702.934145  2630.693350     7.529510    0.273365   \n",
      "min           1.0     9.000000   620.000000  1501.000000    0.000000   \n",
      "25%           1.0   296.000000  3010.000000  1501.000000    0.000000   \n",
      "50%           1.0  3745.000000  3157.000000  1508.000000    0.000000   \n",
      "75%           1.0  3952.500000  7160.000000  1515.000000    0.000000   \n",
      "max           1.0  5073.000000  8958.000000  1522.000000    1.000000   \n",
      "\n",
      "       promo_discount_perc  base_demand  ordered_units  \n",
      "count           542.000000   542.000000            0.0  \n",
      "mean              2.892223   264.342979            NaN  \n",
      "std               9.539602   843.806447            NaN  \n",
      "min               0.000000     0.000000            NaN  \n",
      "25%               0.000000     0.000000            NaN  \n",
      "50%               0.000000     4.406780            NaN  \n",
      "75%               0.000000   119.500000            NaN  \n",
      "max              59.765915  9597.844828            NaN  \n",
      "\n",
      " Visualize the unique classes on each of variables\n",
      "MAG: ['E01' 'E15' 'I26' 'I36' 'M41' 'W91']\n",
      "AG: [ 620  638 3010 3079 3149 3155 3157 3160 3371 3568 3580 3590 5008 5041\n",
      " 5100 7160 7366 7456 8189 8190 8193 8194 8871 8873 8958]\n",
      "product_id: [   9   10   11   13   26   28   40   43   51  143  144  145  149  167\n",
      "  168  175  185  211  213  218  224  229  234  237  239  240  276  277\n",
      "  282  284  286  287  288  289  290  292  294  296  316  609 1640 1645\n",
      " 1947 1948 1960 1964 1967 1973 3233 3234 3240 3241 3244 3245 3248 3250\n",
      " 3257 3260 3264 3266 3267 3270 3278 3290 3673 3681 3686 3691 3712 3714\n",
      " 3720 3734 3739 3740 3741 3745 3764 3765 3766 3768 3788 3789 3794 3802\n",
      " 3808 3809 3813 3827 3833 3835 3838 3842 3843 3879 3881 3891 3893 3903\n",
      " 3905 3906 3909 3914 3922 3924 3927 3928 3929 3930 3940 3944 3951 3953\n",
      " 3962 3964 3969 3978 3982 3984 3986 3988 3992 3993 3996 3999 4000 4006\n",
      " 4007 4008 4010 4012 4016 4022 4023 4024 4900 4903 4907 4912 4914 5024\n",
      " 5025 5030 5032 5033 5036 5067 5072 5073]\n",
      "account_id: [1]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test.describe())\n",
    "\n",
    "# Rajeev: visualize the unique classes on each of variables.\n",
    "print('\\n Visualize the unique classes on each of variables')\n",
    "print('MAG: '+str(np.unique(dataset_test['MAG'])))\n",
    "print('AG: '+str(np.unique(dataset_test['AG'])))\n",
    "print('product_id: '+str(np.unique(dataset_test['product_id'])))\n",
    "print('account_id: '+str(np.unique(dataset_test['account_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     account_id  product_id    MAG     AG  date_id  promo_flag  \\\n",
      "0         False       False  False  False    False       False   \n",
      "1         False       False  False  False    False       False   \n",
      "2         False       False  False  False    False       False   \n",
      "3         False       False  False  False    False       False   \n",
      "4         False       False  False  False    False       False   \n",
      "5         False       False  False  False    False       False   \n",
      "6         False       False  False  False    False       False   \n",
      "7         False       False  False  False    False       False   \n",
      "8         False       False  False  False    False       False   \n",
      "9         False       False  False  False    False       False   \n",
      "10        False       False  False  False    False       False   \n",
      "11        False       False  False  False    False       False   \n",
      "12        False       False  False  False    False       False   \n",
      "13        False       False  False  False    False       False   \n",
      "14        False       False  False  False    False       False   \n",
      "15        False       False  False  False    False       False   \n",
      "16        False       False  False  False    False       False   \n",
      "17        False       False  False  False    False       False   \n",
      "18        False       False  False  False    False       False   \n",
      "19        False       False  False  False    False       False   \n",
      "20        False       False  False  False    False       False   \n",
      "21        False       False  False  False    False       False   \n",
      "22        False       False  False  False    False       False   \n",
      "23        False       False  False  False    False       False   \n",
      "24        False       False  False  False    False       False   \n",
      "25        False       False  False  False    False       False   \n",
      "26        False       False  False  False    False       False   \n",
      "27        False       False  False  False    False       False   \n",
      "28        False       False  False  False    False       False   \n",
      "29        False       False  False  False    False       False   \n",
      "..          ...         ...    ...    ...      ...         ...   \n",
      "512       False       False  False  False    False       False   \n",
      "513       False       False  False  False    False       False   \n",
      "514       False       False  False  False    False       False   \n",
      "515       False       False  False  False    False       False   \n",
      "516       False       False  False  False    False       False   \n",
      "517       False       False  False  False    False       False   \n",
      "518       False       False  False  False    False       False   \n",
      "519       False       False  False  False    False       False   \n",
      "520       False       False  False  False    False       False   \n",
      "521       False       False  False  False    False       False   \n",
      "522       False       False  False  False    False       False   \n",
      "523       False       False  False  False    False       False   \n",
      "524       False       False  False  False    False       False   \n",
      "525       False       False  False  False    False       False   \n",
      "526       False       False  False  False    False       False   \n",
      "527       False       False  False  False    False       False   \n",
      "528       False       False  False  False    False       False   \n",
      "529       False       False  False  False    False       False   \n",
      "530       False       False  False  False    False       False   \n",
      "531       False       False  False  False    False       False   \n",
      "532       False       False  False  False    False       False   \n",
      "533       False       False  False  False    False       False   \n",
      "534       False       False  False  False    False       False   \n",
      "535       False       False  False  False    False       False   \n",
      "536       False       False  False  False    False       False   \n",
      "537       False       False  False  False    False       False   \n",
      "538       False       False  False  False    False       False   \n",
      "539       False       False  False  False    False       False   \n",
      "540       False       False  False  False    False       False   \n",
      "541       False       False  False  False    False       False   \n",
      "\n",
      "     promo_discount_perc  base_demand  ordered_units  \n",
      "0                  False        False           True  \n",
      "1                  False        False           True  \n",
      "2                  False        False           True  \n",
      "3                  False        False           True  \n",
      "4                  False        False           True  \n",
      "5                  False        False           True  \n",
      "6                  False        False           True  \n",
      "7                  False        False           True  \n",
      "8                  False        False           True  \n",
      "9                  False        False           True  \n",
      "10                 False        False           True  \n",
      "11                 False        False           True  \n",
      "12                 False        False           True  \n",
      "13                 False        False           True  \n",
      "14                 False        False           True  \n",
      "15                 False        False           True  \n",
      "16                 False        False           True  \n",
      "17                 False        False           True  \n",
      "18                 False        False           True  \n",
      "19                 False        False           True  \n",
      "20                 False        False           True  \n",
      "21                 False        False           True  \n",
      "22                 False        False           True  \n",
      "23                 False        False           True  \n",
      "24                 False        False           True  \n",
      "25                 False        False           True  \n",
      "26                 False        False           True  \n",
      "27                 False        False           True  \n",
      "28                 False        False           True  \n",
      "29                 False        False           True  \n",
      "..                   ...          ...            ...  \n",
      "512                False        False           True  \n",
      "513                False        False           True  \n",
      "514                False        False           True  \n",
      "515                False        False           True  \n",
      "516                False        False           True  \n",
      "517                False        False           True  \n",
      "518                False        False           True  \n",
      "519                False        False           True  \n",
      "520                False        False           True  \n",
      "521                False        False           True  \n",
      "522                False        False           True  \n",
      "523                False        False           True  \n",
      "524                False        False           True  \n",
      "525                False        False           True  \n",
      "526                False        False           True  \n",
      "527                False        False           True  \n",
      "528                False        False           True  \n",
      "529                False        False           True  \n",
      "530                False        False           True  \n",
      "531                False        False           True  \n",
      "532                False        False           True  \n",
      "533                False        False           True  \n",
      "534                False        False           True  \n",
      "535                False        False           True  \n",
      "536                False        False           True  \n",
      "537                False        False           True  \n",
      "538                False        False           True  \n",
      "539                False        False           True  \n",
      "540                False        False           True  \n",
      "541                False        False           True  \n",
      "\n",
      "[542 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(dataset.isnull()) Rajeev: commented this line since in a long dataframe we cant actually see \n",
    "# which is True and which is False. Below line should print NaN values\n",
    "print(dataset_test.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique products \n",
      "\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "# Let us see how many unique products are there.\n",
    "dataset_test['uniqueprod'] = dataset_test['MAG'].astype(str)+'_'+dataset_test['AG'].astype(str)+'_'+dataset_test['product_id'].astype(str)\n",
    "print('Number of Unique products \\n')\n",
    "print(len(np.unique(dataset_test['uniqueprod'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id   AG  promo_flag  promo_discount_perc  base_demand  E01_638_91  \\\n",
      "0          10  638           0             0.000000          0.0           0   \n",
      "1          10  638           0             0.000000          0.0           0   \n",
      "2          10  638           0             0.000000          0.0           0   \n",
      "3          13  638           0             0.088674          4.0           0   \n",
      "4          13  638           0             0.088674          0.0           0   \n",
      "\n",
      "   E01_638_101  E01_638_131  E01_638_261  E01_620_431  ...  E01_620_40161  \\\n",
      "0            1            0            0            0  ...              0   \n",
      "1            1            0            0            0  ...              0   \n",
      "2            1            0            0            0  ...              0   \n",
      "3            0            1            0            0  ...              0   \n",
      "4            0            1            0            0  ...              0   \n",
      "\n",
      "   E01_620_40221  W91_3010_49121  W91_3010_49141  E01_620_50241  \\\n",
      "0              0               0               0              0   \n",
      "1              0               0               0              0   \n",
      "2              0               0               0              0   \n",
      "3              0               0               0              0   \n",
      "4              0               0               0              0   \n",
      "\n",
      "   I36_5041_50301  E01_7456_50331  E01_620_50361  E01_5100_50721  \\\n",
      "0               0               0              0               0   \n",
      "1               0               0              0               0   \n",
      "2               0               0              0               0   \n",
      "3               0               0              0               0   \n",
      "4               0               0              0               0   \n",
      "\n",
      "   E01_5100_50731  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "\n",
      "[5 rows x 155 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset['uniqueprod'] = dataset['MAG'].astype(str)+'_'+dataset['AG'].astype(str)+'_'+dataset['product_id'].astype(str)\n",
    "mag=list(pd.Series(dataset['uniqueprod']).unique())\n",
    "for i in range(len(mag)):\n",
    "    ttl=mag[i]\n",
    "    ttl1=ttl+'1'\n",
    "    dataset_test[ttl1] = dataset_test['uniqueprod'].str.contains(ttl)\n",
    "    dataset_test[ttl1] = dataset_test[ttl1].map({True: 1, False: 0})\n",
    "\n",
    "del dataset_test['MAG']\n",
    "y= dataset_test['ordered_units']\n",
    "del  dataset_test['ordered_units']\n",
    "del dataset_test['account_id']\n",
    "del dataset_test['date_id']\n",
    "del dataset_test['uniqueprod'] \n",
    "\n",
    "print(dataset_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3039\n",
      "542\n"
     ]
    }
   ],
   "source": [
    "# Fitting Decision Tree Regression to the dataset\n",
    "# below was the regressor we have used earlier.\n",
    "#regressor = RandomForestRegressor(n_estimators=50, max_depth=14,max_features= 0.7, random_state = 1234,n_jobs=-1)\n",
    "X_test = dataset_test\n",
    "print(len(y_test))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3039, 542]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-477-edac0c2d53b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#calculating average absolute error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \"\"\"\n\u001b[0;32m    537\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 538\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    539\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \"\"\"\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3039, 542]"
     ]
    }
   ],
   "source": [
    "#Predicting a new result\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print(metrics.r2_score(y_test,y_pred))\n",
    "\n",
    "#calculating average absolute error \n",
    "error = abs(y_pred - y_test)\n",
    "print(error.mean())\n",
    "print(error.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the OLS summary\n",
    "\n",
    "#import statsmodels.api as sm\n",
    "#X_train = np.append(arr = np.ones((15347,1)).astype(int), values= X_train, axis = 1 )\n",
    "#X_opt = X_train[:, [0,1,2,3]]\n",
    "#regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()\n",
    "#print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding off the Predicted ordered units to nearest integer\n",
    "\n",
    "y_round = [round(x) for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally writing the predicted ordered unit into the test dataset file\n",
    "\n",
    "datafile = pd.read_csv('base_promo_testset.csv')\n",
    "datafile['ordered_units'] = y_round\n",
    "datafile.to_csv('base_promo_testset_pred.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
